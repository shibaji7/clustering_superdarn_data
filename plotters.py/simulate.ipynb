{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sys\n",
    "sys.path.insert(0, '..')\n",
    "from algorithms.dbscan_gmm import DBSCAN_GMM\n",
    "from algorithms.grid_based_dbscan import GridBasedDBSCAN\n",
    "from algorithms.grid_based_dbscan_gmm import GridBasedDBSCAN_GMM\n",
    "from utilities.plot_utils import *\n",
    "from utility import Skills, ScatterDetection\n",
    "import pandas as pd\n",
    "import datetime\n",
    "from plots_report import *\n",
    "from get_sd_data import *\n",
    "from matplotlib.dates import date2num, num2date\n",
    "\n",
    "def estimate_skills(_dict_, labels):\n",
    "    V, W, L = [], [], []\n",
    "    for v, w, l in zip(_dict_[\"vel\"], _dict_[\"wid\"], labels):\n",
    "        V.extend(v.tolist())\n",
    "        W.extend(w.tolist())\n",
    "        L.extend(l.tolist())\n",
    "    V, W, L = np.array(V), np.array(W), np.array(L)\n",
    "    X = np.array([V.tolist(), W.tolist()]).T\n",
    "    sk = Skills(X, L)\n",
    "    return sk\n",
    "\n",
    "def estimate_df_skills(df, labels):\n",
    "    V, W, L = [], [], []\n",
    "    V, W, L = np.array(df.v), np.array(df.w_l), np.array(df.labels)\n",
    "    X = np.array([V.tolist(), W.tolist()]).T\n",
    "    sk = Skills(X, L)\n",
    "    return sk\n",
    "\n",
    "def _filter_by_time(start_time, end_time, data_dict):\n",
    "    time = data_dict['time']\n",
    "    start_i, end_i = None, None\n",
    "    start_time, end_time = date2num(start_time), date2num(end_time)\n",
    "    if start_time < time[0][0]: # Sometimes start time is a few seconds before the first scan\n",
    "        start_time = time[0][0]\n",
    "    for i, t in enumerate(time):\n",
    "        if np.sum(start_time >= t) > 0 and start_i == None:\n",
    "            start_i = i\n",
    "        if np.sum(end_time > t) > 0 and start_i != None:\n",
    "            end_i = i+1\n",
    "    data_dict['gate'] = data_dict['gate'][start_i:end_i]\n",
    "    data_dict['time'] = data_dict['time'][start_i:end_i]\n",
    "    data_dict['beam'] = data_dict['beam'][start_i:end_i]\n",
    "    data_dict['vel'] = data_dict['vel'][start_i:end_i]\n",
    "    data_dict['wid'] = data_dict['wid'][start_i:end_i]\n",
    "    data_dict['elv'] = data_dict['elv'][start_i:end_i]\n",
    "    data_dict['trad_gsflg'] = data_dict['trad_gsflg'][start_i:end_i]\n",
    "    return data_dict\n",
    "\n",
    "def todf(dicts, keys=['gate', 'beam', 'vel', 'wid', 'time', 'trad_gsflg', 'elv', 'pow', 'clust_flg']):\n",
    "    df = pd.DataFrame()\n",
    "    _o = {}\n",
    "    print(dicts.keys())\n",
    "    for k in keys:\n",
    "        _o[k] = []\n",
    "        for x in dicts[k]:\n",
    "            _o[k].extend(x)\n",
    "    df = pd.DataFrame.from_records(_o)\n",
    "    df = df.rename(columns={'gate':\"slist\", 'beam':\"bmnum\", 'vel':'v', 'wid':\"w_l\", \n",
    "                            'time':\"time\", 'pow':\"p_l\", 'clust_flg':\"labels\"})\n",
    "    return df\n",
    "\n",
    "def sma_bbox(scans, sdur=5, idx=None, dbeam=15, window=7):\n",
    "    df = pd.DataFrame()\n",
    "    plot=False\n",
    "    for i in range(int(len(scans)/sdur)):\n",
    "        if (idx is not None) and (i == idx): plot=True\n",
    "        if i == 0: mlf = MiddleLatFilter(rad, scans=scans[i*sdur:(i+1)*sdur], plot=plot)\n",
    "        elif i == int(len(scans)/sdur)-1: mlf._reset_(rad, scans[i*sdur:], plot=plot)\n",
    "        else: mlf._reset_(rad, scans[i*sdur:(i+1)*sdur], plot=plot)\n",
    "        dx = mlf.doFilter(fdata, dbeam=dbeam, window=window)\n",
    "        slist = np.array(dx.slist)\n",
    "        labs = np.array(dx[\"labels\"])\n",
    "        labs[labs<0] = np.nan\n",
    "        labs = labs + (10*i)\n",
    "        labs[np.isnan(labs)] = -1\n",
    "        dx[\"labels\"] = labs\n",
    "        df = pd.concat([df, dx])\n",
    "    return df\n",
    "\n",
    "def lower_range(df, gf=None):\n",
    "    u = df.copy()\n",
    "    slist = np.array(u.slist)\n",
    "    labs = np.array(u[\"labels\"])\n",
    "    if gf is not None: labs[slist<8] = gf\n",
    "    u[\"labels\"] = labs\n",
    "    return u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DBSCAN clusters: 946\n",
      "\n",
      " Estimated Skills.\n",
      " Calinski Harabasz Score -  76.89291596010382\n",
      " Ball-Hall Score -  3428005.4304956687\n",
      " Hartigan Score -  -1.2297724001934704\n",
      " Xu Score -  1.5887023768806188\n",
      " Estimation done.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-773461a9348a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;31m#dbgmm = DBSCAN_GMM(start_time, end_time, rad, BoxCox=True, load_model=False, save_model=True)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;31m#setattr(dbgmm, \"skill\", estimate_skills(dbgmm.data_dict, dbgmm.clust_flg))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0mgbdb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGridBasedDBSCAN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart_time\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend_time\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mload_model\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_model\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m     \u001b[0msetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgbdb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"skill\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mestimate_skills\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgbdb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgbdb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclust_flg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;31m#gbdbgmm = GridBasedDBSCAN_GMM(start_time, end_time, rad, load_model=False, save_model=True)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Clustering/clustering_superdarn_data/algorithms/grid_based_dbscan.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, start_time, end_time, rad, f, g, pts_ratio, dr, dtheta, r_init, scan_eps, load_model, save_model)\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mload_model\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m             \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_i\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_gbdb_data_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m             \u001b[0mclust_flg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mruntime\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gbdb\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_i\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclust_flg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_1D_to_scanxscan\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclust_flg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"clust_flg\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclust_flg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Clustering/clustering_superdarn_data/algorithms/algorithm.py\u001b[0m in \u001b[0;36m_gbdb\u001b[0;34m(self, data, data_i)\u001b[0m\n\u001b[1;32m    346\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mgrid_id\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mm_i\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgrid_labels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mscan_i\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mgrid_id\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mUNCLASSIFIED\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 348\u001b[0;31m                     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_expand_cluster\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrid_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscan_i\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrid_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcluster_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    349\u001b[0m                         \u001b[0mcluster_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcluster_id\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    350\u001b[0m             \u001b[0mscan_pt_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mgrid_labels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mscan_i\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mgrid_id\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mgrid_id\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mm_i\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Clustering/clustering_superdarn_data/algorithms/algorithm.py\u001b[0m in \u001b[0;36m_expand_cluster\u001b[0;34m(self, data, grid_labels, scan_i, grid_id, cluster_id)\u001b[0m\n\u001b[1;32m    385\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseeds\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    386\u001b[0m                 \u001b[0mcurrent_scan\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcurrent_grid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mseeds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseeds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 387\u001b[0;31m                 \u001b[0mresults\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossible_pts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_region_query\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcurrent_scan\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcurrent_grid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    388\u001b[0m                 \u001b[0mk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpossible_pts\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'pts_ratio'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    389\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Clustering/clustering_superdarn_data/algorithms/algorithm.py\u001b[0m in \u001b[0;36m_region_query\u001b[0;34m(self, data, scan_i, grid_id)\u001b[0m\n\u001b[1;32m    421\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_ellipse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrid_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhgt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    422\u001b[0m                         \u001b[0mpossible_pts\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 423\u001b[0;31m                         \u001b[0;32mif\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnew_id\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m   \u001b[0;31m# Add the point to seeds only if there is a 1 in the sparse matrix there\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    424\u001b[0m                             \u001b[0mseeds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    425\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mseeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossible_pts\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/tljh/user/lib/python3.7/site-packages/scipy/sparse/_index.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m     31\u001b[0m     \"\"\"\n\u001b[1;32m     32\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m         \u001b[0mrow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcol\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_indices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m         \u001b[0;31m# Dispatch to specialized methods.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mINT_TYPES\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/tljh/user/lib/python3.7/site-packages/scipy/sparse/_index.py\u001b[0m in \u001b[0;36m_validate_indices\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    126\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_validate_indices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m         \u001b[0mM\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mN\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 128\u001b[0;31m         \u001b[0mrow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcol\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_unpack_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misintlike\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/tljh/user/lib/python3.7/site-packages/scipy/sparse/_index.py\u001b[0m in \u001b[0;36m_unpack_index\u001b[0;34m(index)\u001b[0m\n\u001b[1;32m    248\u001b[0m     \"\"\"\n\u001b[1;32m    249\u001b[0m     \u001b[0;31m# First, check if indexing with single boolean matrix.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 250\u001b[0;31m     \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mbase\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mspmatrix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0misspmatrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    251\u001b[0m     if (isinstance(index, (spmatrix, np.ndarray)) and\n\u001b[1;32m    252\u001b[0m             index.ndim == 2 and index.dtype.kind == 'b'):\n",
      "\u001b[0;32m/opt/tljh/user/lib/python3.7/importlib/_bootstrap.py\u001b[0m in \u001b[0;36mparent\u001b[0;34m(self)\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "case = 0*1\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "if case == 0:\n",
    "    start_time = datetime.datetime(2017, 4, 4)\n",
    "    end_time = datetime.datetime(2017, 4, 5)\n",
    "    rad, bm = \"cvw\",7\n",
    "\n",
    "    #db = DBSCAN_GMM(start_time, end_time, rad, BoxCox=True, load_model=False, save_model=True, run_gmm=False)\n",
    "    #setattr(db, \"skill\", estimate_skills(db.data_dict, db.clust_flg))\n",
    "    dbgmm = DBSCAN_GMM(start_time, end_time, rad, BoxCox=True, load_model=False, save_model=True)\n",
    "    setattr(dbgmm, \"skill\", estimate_skills(dbgmm.data_dict, dbgmm.clust_flg))\n",
    "    #gbdb = GridBasedDBSCAN(start_time, end_time, rad, load_model=False, save_model=True)\n",
    "    #setattr(gbdb, \"skill\", estimate_skills(gbdb.data_dict, gbdb.clust_flg))\n",
    "    #gbdbgmm = GridBasedDBSCAN_GMM(start_time, end_time, rad, load_model=False, save_model=True)\n",
    "    #setattr(gbdbgmm, \"skill\", estimate_skills(gbdbgmm.data_dict, gbdbgmm.clust_flg))\n",
    "\n",
    "    rti = RangeTimePlot(110, np.unique(np.hstack(db.data_dict[\"time\"])), \"\", num_subplots=7)\n",
    "    dx = todf(db.data_dict)\n",
    "    #rti.addParamPlot(dx, bm, \"Velocity\", p_max=100, p_min=-100, p_step=25, xlabel=\"\", zparam=\"v\", label='Velocity [m/s]')\n",
    "    #rti.addParamPlot(dx, bm, \"Power\", p_max=30, p_min=3, p_step=3, xlabel=\"\", zparam=\"p_l\", label='Power [dB]')\n",
    "    #rti.addParamPlot(dx, bm, \"Spec. Width\", p_max=100, p_min=0, p_step=10, xlabel=\"\", zparam=\"w_l\", label='Spec. Width [m/s]')\n",
    "    rti.addCluster(dx, bm, \"DBSCAN\", label_clusters=True, skill=db.skill)\n",
    "    rti.addCluster(todf(dbgmm.data_dict), bm, \"DBSCAN + GMM\", label_clusters=True, skill=dbgmm.skill)\n",
    "    #rti.addCluster(todf(gbdb.data_dict), bm, \"GB-DBSCAN\", label_clusters=True, skill=gbdb.skill)\n",
    "    #rti.addCluster(todf(gbdbgmm.data_dict), bm, \"GB-DBSCAN + GMM \", label_clusters=True, xlabel=\"Time, UT\", \n",
    "    #    skill=gbdbgmm.skill)\n",
    "    rti.save(\"figs/rti.example.png\")\n",
    "if case == 1:\n",
    "    plot_acfs(rad=\"kap\")\n",
    "    plot_lims(False)\n",
    "    plot_lims(True)\n",
    "    plot_rad_acfs()\n",
    "    plot_hist_hr()\n",
    "if case == 2:\n",
    "    start_time = datetime.datetime(2015, 3, 17)\n",
    "    end_time = datetime.datetime(2015, 3, 17, 12)\n",
    "    rad, bm = \"bks\",15\n",
    "\n",
    "    db = DBSCAN_GMM(start_time, end_time, rad, BoxCox=True, load_model=False, save_model=True, run_gmm=False)\n",
    "    rti = RangeTimePlot(110, np.unique(np.hstack(db.data_dict[\"time\"])), \"\", num_subplots=3)\n",
    "    rti.addClusterPlot(db.data_dict, db.clust_flg, bm, \"DBSCAN\", label_clusters=True, skill=None)\n",
    "    rti.addGSISPlot(db.data_dict, db.data_dict[\"trad_gsflg\"], bm, \"GS-ID:Traditioanl\", show_closerange=True, xlabel='')\n",
    "    rti.addVelPlot(db.data_dict, bm, \"Velocity\", vel_max=200, vel_step=50, xlabel='Time UT')\n",
    "    rti.save(\"figs/dbscan.trad.png\")\n",
    "if case == 3:\n",
    "    start_time = datetime.datetime(2015, 3, 17)\n",
    "    end_time = datetime.datetime(2015, 3, 17, 12)\n",
    "    rad, bm = \"bks\",7\n",
    "    kinds = [\"dbscan\", \"dbscan-gmm\", \"gb-dbscan\", \"gb-dbscan-gmm\"]\n",
    "    kinds = [\"dbscan\"]\n",
    "    for kind in kinds:    \n",
    "        if kind == \"dbscan\": db = DBSCAN_GMM(start_time, end_time, rad, BoxCox=True, load_model=False, save_model=True, run_gmm=False)\n",
    "        if kind == \"dbscan-gmm\": db = DBSCAN_GMM(start_time, end_time, rad, BoxCox=True, load_model=False, save_model=True, run_gmm=True)\n",
    "        if kind == \"gb-dbscan\": db = GridBasedDBSCAN(start_time, end_time, rad, load_model=False, save_model=True)\n",
    "        if kind == \"gb-dbscan-gmm\": db = GridBasedDBSCAN_GMM(start_time, end_time, rad, load_model=False, save_model=True,\n",
    "                features=['beam', 'gate', 'time','vel','wid'], scan_eps=10)\n",
    "        sd = ScatterDetection(db.data_dict)\n",
    "        #rti = RangeTimePlot(110, np.unique(np.hstack(db.data_dict[\"time\"])), \"\", num_subplots=6)\n",
    "        #rti.addClusterPlot(db.data_dict, db.clust_flg, bm, kind.upper(), label_clusters=True, skill=None)\n",
    "        #rti.addGSISPlot(db.data_dict, sd.run(kind=1, case=0), bm, \"GS-ID:Median(Sudden)\", show_closerange=True, xlabel='')\n",
    "        #rti.addGSISPlot(db.data_dict, sd.run(kind=1, case=1), bm, \"GS-ID:Median(Blanchard 2006)\", show_closerange=True, xlabel='')\n",
    "        #rti.addGSISPlot(db.data_dict, sd.run(kind=1, case=2), bm, \"GS-ID:Median(Blanchard 2009)\", show_closerange=True, xlabel='')\n",
    "        #rti.addGSISPlot(db.data_dict, sd.run(kind=1, case=3), bm, \"GS-ID:Median(Proposed)\", show_closerange=True, xlabel='')\n",
    "        #rti.addVelPlot(db.data_dict, bm, \"Velocity\", vel_max=200, vel_step=50, xlabel='Time UT')\n",
    "        #rti.save(\"figs/%s.median.png\"%kind)\n",
    "\n",
    "        #rti = RangeTimePlot(110, np.unique(np.hstack(db.data_dict[\"time\"])), \"\", num_subplots=6)\n",
    "        #rti.addClusterPlot(db.data_dict, db.clust_flg, bm, kind.upper(), label_clusters=True, skill=None)\n",
    "        #rti.addGSISPlot(db.data_dict, sd.run(kind=2, thresh=[0.1,0.9], case=0), bm, \"GS-ID:Median(Sudden)\", show_closerange=True, xlabel='')\n",
    "        #rti.addGSISPlot(db.data_dict, sd.run(kind=2, thresh=[0.1,0.9], case=1), bm, \"GS-ID:Median(Blanchard 2006)\",\n",
    "        #        show_closerange=True, xlabel='')\n",
    "        #rti.addGSISPlot(db.data_dict, sd.run(kind=2, thresh=[0.1,0.9], case=2), bm, \"GS-ID:Median(Blanchard 2009)\", \n",
    "        #        show_closerange=True, xlabel='')\n",
    "        #rti.addGSISPlot(db.data_dict, sd.run(kind=2, case=3), bm, \"GS-ID:Median(Proposed)\", show_closerange=True, xlabel='')\n",
    "        #rti.addVelPlot(db.data_dict, bm, \"Velocity\", vel_max=200, vel_step=50, xlabel='Time UT')\n",
    "        #rti.save(\"figs/%s.kde.png\"%kind)\n",
    "\n",
    "        rti = RangeTimePlot(110, np.unique(np.hstack(db.data_dict[\"time\"])), \"\", num_subplots=6)\n",
    "        rti.addClusterPlot(db.data_dict, db.clust_flg, bm, kind.upper(), label_clusters=True, skill=None)\n",
    "        rti.addGSISPlot(db.data_dict, sd.run(kind=0, case=0), bm, \"GS-ID:Sudden\", show_closerange=True, xlabel='')\n",
    "        rti.addGSISPlot(db.data_dict, sd.run(kind=0, case=1), bm, \"GS-ID:Blanchard 2006\", show_closerange=True, xlabel='')\n",
    "        rti.addGSISPlot(db.data_dict, sd.run(kind=0, case=2), bm, \"GS-ID:Blanchard 2009\", show_closerange=True, xlabel='')\n",
    "        rti.addGSISPlot(db.data_dict, sd.run(kind=0, case=3), bm, \"GS-ID:Proposed\", show_closerange=True, xlabel='')\n",
    "        rti.addVelPlot(db.data_dict, bm, \"Velocity\", vel_max=200, vel_step=50, xlabel='Time UT')\n",
    "        rti.save(\"figs/%s.indp.png\"%kind)\n",
    "if case == 4:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sma import MiddleLatFilter\n",
    "#start_time = datetime.datetime(2015, 3, 17)\n",
    "#end_time = datetime.datetime(2015, 3, 17, 10)\n",
    "#rad, bm = \"bks\",7\n",
    "\n",
    "#start_time = datetime.datetime(2017, 4, 4)\n",
    "#end_time = datetime.datetime(2017, 4, 5)\n",
    "#rad, bm = \"cvw\",7\n",
    "\n",
    "#fdata = FetchData( rad, [start_time, end_time] )\n",
    "#_, scans = fdata.fetch_data(by=\"scan\", scan_prop={\"dur\": 2, \"stype\": \"themis\"})\n",
    "#print(\" Total numbe of scans: \", len(scans))\n",
    "#import pickle\n",
    "#data_dict = pickle.load(open(\"../data/bks_2015-03-17_scans.pickle\", 'rb'))\n",
    "#data_dict = _filter_by_time(start_time, end_time, data_dict)\n",
    "\n",
    "#import os\n",
    "#os.system(\"rm figs/bks*\")\n",
    "#df = sma_bbox(scans, sdur=15, idx=None)\n",
    "#from sma import ScatterTypeDetection\n",
    "#bm=7\n",
    "#sd = ScatterTypeDetection(df)\n",
    "#rti = RangeTimePlot(110, np.unique(np.hstack(data_dict[\"time\"])), \"\", num_subplots=3)\n",
    "#rti.addParamPlot(df, bm, \"Velocity\", vel_max=100, vel_step=20, xlabel=\"\")\n",
    "#rti.addCluster(df, bm, \"SMA\", xlabel=\"\")\n",
    "#rti.addGSIS(sd.run(kind=0, case=0), bm, r\"GsI:[Sudden]\")\n",
    "#rti.addGSIS(sd.run(kind=0, case=1), bm, r\"GsI:[Blanchard 2006]\")\n",
    "#rti.addGSIS(sd.run(kind=0, case=2), bm, r\"GsI:[Blanchard 2009]\", xlabel='Time, UT')\n",
    "#rti.addGSIS(sd.run(kind=0, case=3), bm, r\"GsI:[X]\", xlabel='Time, UT')\n",
    "#rti.save(\"figs/bks_sma_01.png\")\n",
    "#rti.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run = False\n",
    "if run:\n",
    "    from sma import MiddleLatFilter\n",
    "    start_time = datetime.datetime(2017, 4, 4)\n",
    "    end_time = datetime.datetime(2017, 4, 5)\n",
    "    rad, bm = \"cvw\",7\n",
    "\n",
    "    fdata = FetchData( rad, [start_time, end_time] )\n",
    "    _, scans = fdata.fetch_data(by=\"scan\", scan_prop={\"dur\": 2, \"stype\": \"themis\"})\n",
    "    print(\" Total numbe of scans: \", len(scans))\n",
    "    import pickle\n",
    "    data_dict = pickle.load(open(\"../data/cvw_2017-04-04_scans.pickle\", 'rb'))\n",
    "    data_dict = _filter_by_time(start_time, end_time, data_dict)\n",
    "\n",
    "    import os\n",
    "    os.system(\"rm figs/cvw*\")\n",
    "    df = sma_bbox(scans, sdur=30, idx=None, dbeam=None, window=5)\n",
    "    from sma import ScatterTypeDetection\n",
    "    rti = RangeTimePlot(110, np.unique(np.hstack(data_dict[\"time\"])), \"\", num_subplots=4)\n",
    "    rti.addParamPlot(df, bm, \"Velocity\", p_max=100, p_min=-100, p_step=25, xlabel=\"\", zparam=\"v\", label='Velocity [m/s]')\n",
    "    rti.addParamPlot(df, bm, \"Power\", p_max=30, p_min=3, p_step=3, xlabel=\"\", zparam=\"p_l\", label='Power [dB]')\n",
    "    rti.addParamPlot(df, bm, \"Spec. Width\", p_max=100, p_min=0, p_step=10, xlabel=\"\", zparam=\"w_l\", label='Spec. Width [m/s]')\n",
    "    rti.addCluster(lower_range(df, -1), bm, \"SMA\", label_clusters=True, skill=estimate_df_skills(df, df.labels), xlabel='Time, UT')\n",
    "    rti.save(\"figs/cvw_07_sma.png\")\n",
    "    rti.close()\n",
    "    sd = ScatterTypeDetection(df)\n",
    "    rti = RangeTimePlot(110, np.unique(np.hstack(data_dict[\"time\"])), \"\", num_subplots=5)\n",
    "    rti.addCluster(lower_range(df, -1), bm, \"SMA\", label_clusters=True, skill=estimate_df_skills(df, df.labels))\n",
    "    rti.addGSIS(sd.run(kind=1, case=0), bm, r\"GsI:[Sudden]\")\n",
    "    rti.addGSIS(sd.run(kind=1, case=1), bm, r\"GsI:[Blanchard 2006]\")\n",
    "    rti.addGSIS(sd.run(kind=1, case=2), bm, r\"GsI:[Blanchard 2009]\")\n",
    "    sd = ScatterTypeDetection(lower_range(df, -1))\n",
    "    rti.addGSIS(sd.run(kind=1, case=3, mod=True), bm, r\"GsI:[Chakraborty]\", xlabel='Time, UT')\n",
    "    rti.save(\"figs/cvw_07_sma_is.png\")\n",
    "    rti.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run = False\n",
    "if run:\n",
    "    from sma import MiddleLatFilter\n",
    "    start_time = datetime.datetime(2015, 3, 17)\n",
    "    end_time = datetime.datetime(2015, 3, 17, 12)\n",
    "    rad, bm = \"bks\",15\n",
    "\n",
    "    fdata = FetchData( rad, [start_time, end_time] )\n",
    "    _, scans = fdata.fetch_data(by=\"scan\", scan_prop={\"dur\": 2, \"stype\": \"themis\"})\n",
    "    print(\" Total numbe of scans: \", len(scans))\n",
    "    import pickle\n",
    "    data_dict = pickle.load(open(\"../data/bks_2015-03-17_scans.pickle\", 'rb'))\n",
    "    data_dict = _filter_by_time(start_time, end_time, data_dict)\n",
    "\n",
    "    import os\n",
    "    os.system(\"rm figs/bks*\")\n",
    "    df = sma_bbox(scans, sdur=30, idx=None, dbeam=15, window=5)\n",
    "    from sma import ScatterTypeDetection\n",
    "    rti = RangeTimePlot(110, np.unique(np.hstack(data_dict[\"time\"])), \"\", num_subplots=4)\n",
    "    rti.addParamPlot(df, bm, \"Velocity\", p_max=100, p_min=-100, p_step=25, xlabel=\"\", zparam=\"v\", label='Velocity [m/s]')\n",
    "    rti.addParamPlot(df, bm, \"Power\", p_max=30, p_min=3, p_step=3, xlabel=\"\", zparam=\"p_l\", label='Power [dB]')\n",
    "    rti.addParamPlot(df, bm, \"Spec. Width\", p_max=100, p_min=0, p_step=10, xlabel=\"\", zparam=\"w_l\", label='Spec. Width [m/s]')\n",
    "    rti.addCluster(lower_range(df, -1), bm, \"SMA\", label_clusters=True, skill=estimate_df_skills(df, df.labels), xlabel='Time, UT')\n",
    "    rti.save(\"figs/bks_07_sma.png\")\n",
    "    rti.close()\n",
    "    sd = ScatterTypeDetection(df)\n",
    "    rti = RangeTimePlot(110, np.unique(np.hstack(data_dict[\"time\"])), \"\", num_subplots=5)\n",
    "    rti.addCluster(lower_range(df, -1), bm, \"SMA\", label_clusters=True, skill=estimate_df_skills(df, df.labels))\n",
    "    rti.addGSIS(sd.run(kind=1, case=0), bm, r\"GsI:[Sudden]\")\n",
    "    rti.addGSIS(sd.run(kind=1, case=1), bm, r\"GsI:[Blanchard 2006]\")\n",
    "    rti.addGSIS(sd.run(kind=1, case=2), bm, r\"GsI:[Blanchard 2009]\")\n",
    "    sd = ScatterTypeDetection(lower_range(df, -1))\n",
    "    rti.addGSIS(sd.run(kind=1, case=3, mod=False), bm, r\"GsI:[Chakraborty]\", xlabel='Time, UT')\n",
    "    rti.save(\"figs/bks_07_sma_is.png\")\n",
    "    rti.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gsoc",
   "language": "python",
   "name": "gsoc"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
